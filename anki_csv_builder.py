import streamlit as st
import pandas as pd
import re
import csv
import io
import json
import time
import hashlib
from typing import List, Dict, Tuple
from openai import OpenAI
from prompts import compose_instructions_en, PROMPT_PROFILES as PR_PROMPT_PROFILES

# ==========================
# Optional: Anki export (genanki)
# ==========================
try:
    import genanki  # type: ignore
    HAS_GENANKI = True
except Exception:
    HAS_GENANKI = False

# ==========================
# Config (import with safe fallbacks)
# ==========================
try:
    # –í–∞—à —Ñ–∞–π–ª —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏. –ú–æ–∂–Ω–æ —Å–≤–æ–±–æ–¥–Ω–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–∫–∏/–ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—é –∑–¥–µ—Å—å.
    from config import (
        DEFAULT_MODELS as CFG_DEFAULT_MODELS,
        _PREFERRED_ORDER as CFG_PREFERRED_ORDER,
        _BLOCK_SUBSTRINGS as CFG_BLOCK_SUBSTRINGS,
        _ALLOWED_PREFIXES as CFG_ALLOWED_PREFIXES,
        SIGNALWORDS_B1 as CFG_SIGNALWORDS_B1,
        SIGNALWORDS_B2_PLUS as CFG_SIGNALWORDS_B2_PLUS,
        PROMPT_PROFILES as CFG_PROMPT_PROFILES,
        L1_LANGS as CFG_L1_LANGS,
        CSV_HEADERS_LOCALIZATION as CFG_CSV_HEADERS_LOCALIZATION,
        CSV_HEADERS_FIXED as CFG_CSV_HEADERS_FIXED,
        PAGE_TITLE as CFG_PAGE_TITLE,
        PAGE_LAYOUT as CFG_PAGE_LAYOUT,
        TEMPERATURE_MIN as CFG_TMIN,
        TEMPERATURE_MAX as CFG_TMAX,
        TEMPERATURE_DEFAULT as CFG_TDEF,
        TEMPERATURE_STEP as CFG_TSTEP,
        PREVIEW_LIMIT as CFG_PREVIEW_LIMIT,
        API_REQUEST_DELAY as CFG_API_DELAY,
        FRONT_HTML_TEMPLATE as CFG_FRONT_HTML_TEMPLATE,
        BACK_HTML_TEMPLATE as CFG_BACK_HTML_TEMPLATE,
        CSS_STYLING as CFG_CSS_STYLING,
        MESSAGES as CFG_MESSAGES,
        ANKI_MODEL_ID as CFG_ANKI_MODEL_ID,
        ANKI_DECK_ID as CFG_ANKI_DECK_ID,
        ANKI_MODEL_NAME as CFG_ANKI_MODEL_NAME,
        ANKI_DECK_NAME as CFG_ANKI_DECK_NAME,
        DEMO_WORDS as CFG_DEMO_WORDS,
    )
except Exception:
    # Fallback –∑–Ω–∞—á–µ–Ω–∏—è, –µ—Å–ª–∏ config.py –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/–Ω–µ–ø–æ–ª–Ω—ã–π
    CFG_DEFAULT_MODELS = [
        "gpt-5", "gpt-5-mini", "gpt-5-nano", "gpt-4.1", "gpt-4o", "gpt-4o-mini", "o3-mini"
    ]
    CFG_PREFERRED_ORDER = {
        "gpt-5": 0, "gpt-5-mini": 1, "gpt-5-nano": 2, "gpt-4.1": 3, "gpt-4o": 4, "gpt-4o-mini": 5, "o3": 6, "o3-mini": 7
    }
    CFG_BLOCK_SUBSTRINGS = (
        "audio", "realtime", "embed", "embedding", "whisper", "asr", "transcribe",
        "speech", "tts", "moderation", "search", "vision", "vision-preview", "distill", "distilled",
        "batch", "preview"
    )
    CFG_ALLOWED_PREFIXES = ("gpt-5", "gpt-4.1", "gpt-4o", "o3")
    CFG_SIGNALWORDS_B1 = ["omdat", "maar", "dus", "want", "terwijl", "daarom", "daardoor", "toch"]
    CFG_SIGNALWORDS_B2_PLUS = [
        "hoewel", "zodat", "doordat", "bovendien", "echter", "bijvoorbeeld", "tenzij", "ondanks",
        "desondanks", "daarentegen", "aangezien", "zodra", "voordat", "nadat", "enerzijds ... anderzijds",
        "niet alleen ... maar ook", "opdat"
    ]
    CFG_PROMPT_PROFILES = {
        "strict": "Be literal and concise; avoid figurative language; keep the simplest structure that satisfies CEFR.",
        "balanced": "Natural and clear; minor synonymy allowed if it improves fluency.",
        "exam": "Neutral-formal register; precise; avoid colloquialisms.",
        "creative": "Allow mild figurativeness if it keeps clarity and CEFR constraints.",
    }
    CFG_L1_LANGS = {
        "RU": {"label": "RU", "name": "Russian", "csv_translation": "–ü–µ—Ä–µ–≤–æ–¥", "csv_gloss": "–ü–µ—Ä–µ–≤–æ–¥ —Å–ª–æ–≤–∞"},
        "EN": {"label": "EN", "name": "English", "csv_translation": "Translation", "csv_gloss": "Word gloss"},
        "ES": {"label": "ES", "name": "Spanish", "csv_translation": "Traducci√≥n", "csv_gloss": "Glosa"},
        "DE": {"label": "DE", "name": "German", "csv_translation": "√úbersetzung", "csv_gloss": "Kurzgloss"},
    }
    CFG_CSV_HEADERS_LOCALIZATION = CFG_L1_LANGS
    CFG_PAGE_TITLE = "Anki CSV Builder ‚Äî Cloze (NL)"
    CFG_PAGE_LAYOUT = "wide"
    CFG_TMIN, CFG_TMAX, CFG_TDEF, CFG_TSTEP = 0.2, 0.8, 0.4, 0.1
    CFG_PREVIEW_LIMIT = 20
    CFG_API_DELAY = 0.0
    # Fallback –¥–ª—è —à–∞–±–ª–æ–Ω–æ–≤, –µ—Å–ª–∏ –Ω–µ—Ç config.py
    CFG_FRONT_HTML_TEMPLATE = """
<div class="card-inner">
  {{cloze:L2_cloze}}
  <div class="hints">
    {{#L1_gloss}}
    <details class="hint">
      <summary>{L1_LABEL}</summary>
      <div class="hint-body">{{L1_gloss}}</div>
    </details>
    {{/L1_gloss}}

    {{#L2_definition}}
    <details class="hint">
      <summary>NL</summary>
      <div class="hint-body">{{L2_definition}}</div>
    </details>
    {{/L2_definition}}
  </div>
</div>
""".strip()
    CFG_BACK_HTML_TEMPLATE = """
<div class="card-inner">
  {{cloze:L2_cloze}}
  <div class="answer">
    {{#L1_sentence}}
    <div class="section ru">{{L1_sentence}}</div>
    {{/L1_sentence}}

    {{#L2_collocations}}
    <div class="section">
      <ul class="colloc" id="colloc-list"></ul>
      <script id="colloc-raw" type="text/plain">{{L2_collocations}}</script>
      <script>
        (function () {
          var rawEl = document.getElementById('colloc-raw');
          if (!rawEl) return;
          var raw = rawEl.textContent || "";
          var items = raw.split(/;\s*|\n+/).map(function (s) { return s.trim(); }).filter(Boolean);
          var ul = document.getElementById('colloc-list');
          if (!ul) return;
          for (var i = 0; i < items.length; i++) {
            var li = document.createElement('li');
            li.textContent = items[i];
            ul.appendChild(li);
          }
        })();
      </script>
    </div>
    {{/L2_collocations}}

    {{#L2_definition}}
    <div class="section def">{{L2_definition}}</div>
    {{/L2_definition}}

    {{#L2_word}}
    <div class="section lemma">
      <span class="lemma-nl">{{L2_word}}</span> ‚Äî <span class="lemma-ru">{{L1_gloss}}</span>
    </div>
    {{/L2_word}}
  </div>
</div>
""".strip()
    CFG_CSS_STYLING = """
/* ===== –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–µ—Ä—Å—Ç–∫–∞ ===== */
:root{
  --fs-base: clamp(18px, 1.2vw + 1.1vh, 28px);
  --fs-sm: calc(var(--fs-base) * .9);
  --fs-lg: calc(var(--fs-base) * 1.12);
  --hl-col:#1976d2;
  --hl-bg:rgba(25,118,210,.14);
}
html, body { height:100%; }
.card{ font-size: var(--fs-base); line-height: 1.55; margin:0; min-height:100vh; display:flex; justify-content:center; align-items:flex-start; background: transparent; }
.card-inner{ width: min(92vw, 80ch); padding: 2.5vh 3vw; }
.answer { margin-top:.75em; }
.section + .section { margin-top:.55em; padding-top:.45em; border-top:1px solid rgba(0,0,0,.14); }
@media (prefers-color-scheme: dark){ .section + .section { border-top-color: rgba(255,255,255,.22); } }
.ru { font-weight:600; font-size: var(--fs-lg); }
.def { font-style: italic; opacity:.9; font-size: var(--fs-sm); }
.lemma { font-weight:600; }
.lemma-nl{ color:var(--hl-col); font-variant: small-caps; letter-spacing:.02em; }
.lemma-ru{ opacity:.9; }
.colloc{ margin:.1em 0 0 1.1em; padding:0; }
.colloc li{ margin:.12em 0; }
.cloze{ color:var(--hl-col); font-weight:700; }
mark.hl{ background:var(--hl-bg); color:inherit; padding:0 .12em; border-radius:.18em; }
.def-hint { margin-top:.5em; }
.def-hint b { opacity:.8; margin-right:.35em; }
.def-toggle{ list-style:none; cursor:pointer; display:inline-block; }
.def-toggle::-webkit-details-marker{ display:none; }
.def-toggle::before{ content: attr(data-closed); text-decoration: underline dotted; }
.def-details[open] .def-toggle::before{ content: attr(data-open); text-decoration:none; opacity:.75; }
img{ max-width:100%; height:auto; }
@media (max-width: 420px){ .card-inner{ width: 94vw; padding: 2vh 3vw; } }
.hints{ margin-top:.6em; display:flex; gap:1em 1.2em; flex-wrap:wrap; align-items:flex-start; }
.hint summary{ cursor:pointer; text-decoration: underline dotted; list-style:none; display:inline-block; }
.hint summary::-webkit-details-marker{ display:none; }
.hint[open] summary{ opacity:.75; text-decoration:none; }
.hint-body{ margin-top:.25em; font-size: var(--fs-sm); }
""".strip()
    # Fallback: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ CSV (NL-–∫–æ–ª–æ–Ω–∫–∏)
    CFG_CSV_HEADERS_FIXED = {
        "nl_word": "NL-—Å–ª–æ–≤–æ",
        "nl_sentence_cloze": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ NL (—Å cloze)",
        "collocations_nl": "–ö–æ–ª–ª–æ–∫–∞—Ü–∏–∏ (NL)",
        "definition_nl": "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ NL",
    }
    # Fallback: —Ç–µ–∫—Å—Ç—ã UI/—Å–æ–æ–±—â–µ–Ω–∏–π
    CFG_MESSAGES = {
        "app_title": "üìò Anki CSV/Anki Builder ‚Äî Dutch Cloze Cards",
        "sidebar_api_header": "üîê API Settings",
        "api_key_label": "OpenAI API Key",
        "model_label": "Model",
        "model_help": "–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ ‚Äî gpt-5; –±–∞–ª–∞–Ω—Å ‚Äî gpt-4.1; –±—ã—Å—Ç—Ä–µ–µ ‚Äî gpt-4o / gpt-5-mini.",
        "profile_label": "Prompt profile",
        "cefr_label": "CEFR",
        "l1_label": "Your language (L1)",
        "temp_label": "Temperature",
        "csv_header_checkbox": "CSV: –≤–∫–ª—é—á–∏—Ç—å —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞",
        "csv_header_help": "–°–Ω–∏–º–∏—Ç–µ –≥–∞–ª–æ—á–∫—É, –µ—Å–ª–∏ Anki –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–ø–∏—Å—å.",
        "anki_guid_policy_label": "Anki GUID policy",
        "anki_guid_policy_options": [
            "stable (update/skip existing)",
            "unique per export (import as new)"
        ],
        "anki_guid_policy_help": (
            "stable: —Ç–µ –∂–µ –∑–∞–º–µ—Ç–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç—Å—è –∫–∞–∫ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ/–æ–±–Ω–æ–≤–ª—è–µ–º—ã–µ\n"
            "unique: –∫–∞–∂–¥—ã–π —ç–∫—Å–ø–æ—Ä—Ç –ø–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤—ã–π GUID ‚Äî Anki —Å—á–∏—Ç–∞–µ—Ç –∏—Ö –Ω–æ–≤—ã–º–∏ –∑–∞–º–µ—Ç–∫–∞–º–∏."
        ),
        "uploader_label": "Upload .txt / .md",
        "recognized_rows_title": "üîç –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏",
        "upload_hint": "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ **Try demo**",
        "try_demo_button": "Try demo",
        "clear_button": "–û—á–∏—Å—Ç–∏—Ç—å",
        "generate_button": "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–æ—á–∫–∏",
        "no_api_key": "–£–∫–∞–∂–∏ OPENAI_API_KEY –≤ Secrets –∏–ª–∏ –≤ –ø–æ–ª–µ —Å–ª–µ–≤–∞.",
        "preview_title_fmt": "üìã –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∫–∞—Ä—Ç–æ—á–µ–∫ (–ø–µ—Ä–≤—ã–µ {limit})",
        "csv_download_label": "üì• –°–∫–∞—á–∞—Ç—å anki_cards.csv",
        "apkg_download_label": "üß© –°–∫–∞—á–∞—Ç—å –∫–æ–ª–æ–¥—É Anki (.apkg)",
        "apkg_install_hint": "–î–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ .apkg –¥–æ–±–∞–≤—å –≤ requirements.txt —Å—Ç—Ä–æ–∫—É 'genanki' –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.",
        "error_card_processing_fmt": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–ª–æ–≤–∞ '{woord}': {error}",
        "error_apkg_build_fmt": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å .–∞–økg: {error}",
        "demo_loaded": "üîÅ –î–µ–º–æ-–Ω–∞–±–æ—Ä –∏–∑ 6 —Å–ª–æ–≤ –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω",
        "footer_tips": (
            "–õ–∞–π—Ñ—Ö–∞–∫–∏: 1) –ß–µ–º –ª—É—á—à–µ NL-–¥–µ—Ñ–∏–Ω–∏—Ü–∏–∏ –Ω–∞ –≤—Ö–æ–¥–µ, —Ç–µ–º —Ç–æ—á–Ω–µ–µ –ø—Ä–∏–º–µ—Ä –∏ –≥–ª–æ—Å—Å. "
            "2) –ù–∞ —É—Ä–æ–≤–Ω—è—Ö B1+ –ø—Ä–∏–º–µ—Ä–Ω–æ –ø–æ–ª–æ–≤–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –±—É–¥–µ—Ç —Å–æ signaalwoorden. "
            "3) –î–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π (gpt-5/o3) —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∏ –±—É–¥–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è."
        ),
    }
    # Fallback: –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã/–∏–º–µ–Ω–∞ Anki
    CFG_ANKI_MODEL_ID = 1607392319
    CFG_ANKI_DECK_ID = 1970010101
    CFG_ANKI_MODEL_NAME = "Dutch Cloze (L2/L1)"
    CFG_ANKI_DECK_NAME = "Dutch ‚Ä¢ Cloze"
    # Fallback: –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ
    CFG_DEMO_WORDS = [
        {"woord": "aanraken", "def_nl": "iets met je hand of een ander deel van je lichaam voelen"},
        {"woord": "begrijpen", "def_nl": "snappen wat iets betekent of inhoudt"},
        {"woord": "gillen", "def_nl": "hard en hoog schreeuwen"},
        {"woord": "kloppen", "def_nl": "met regelmaat bonzen of tikken"},
        {"woord": "toestaan", "def_nl": "goedkeuren of laten gebeuren"},
        {"woord": "opruimen", "def_nl": "iets netjes maken door het op zijn plaats te leggen"},
    ]

# ==========================
# Streamlit page config
# ==========================
st.set_page_config(page_title=CFG_PAGE_TITLE, layout=CFG_PAGE_LAYOUT)

# ==========================
# Models: defaults + dynamic fetch
# ==========================
DEFAULT_MODELS: List[str] = CFG_DEFAULT_MODELS
_PREFERRED_ORDER = CFG_PREFERRED_ORDER
_BLOCK_SUBSTRINGS = CFG_BLOCK_SUBSTRINGS
_ALLOWED_PREFIXES = CFG_ALLOWED_PREFIXES


def _sort_key(model_id: str) -> tuple:
    for k, rank in _PREFERRED_ORDER.items():
        if model_id.startswith(k):
            return (rank, model_id)
    return (999, model_id)


def get_model_options(api_key: str | None) -> List[str]:
    """–ü–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ API, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥ —Ç–µ–∫—Å—Ç–æ–≤—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é."""
    if not api_key:
        return DEFAULT_MODELS
    try:
        client = OpenAI(api_key=api_key)
        models = client.models.list()
        ids = []
        for m in getattr(models, "data", []) or []:
            mid = getattr(m, "id", "")
            if any(mid.startswith(p) for p in _ALLOWED_PREFIXES) and not any(b in mid for b in _BLOCK_SUBSTRINGS):
                ids.append(mid)
        if not ids:
            return DEFAULT_MODELS
        return sorted(set(ids), key=_sort_key)
    except Exception:
        return DEFAULT_MODELS

# ==========================
# Signaalwoorden –∏ –ø—Ä–æ—Ñ–∏–ª–∏
# ==========================
SIGNALWORDS_B1: List[str] = CFG_SIGNALWORDS_B1
SIGNALWORDS_B2_PLUS: List[str] = CFG_SIGNALWORDS_B2_PLUS
PROMPT_PROFILES = PR_PROMPT_PROFILES

L1_LANGS = CFG_L1_LANGS  # code -> {label, name, csv_translation, csv_gloss}

# ==========================
# Sidebar (API, model, params)
# ==========================
st.sidebar.header(CFG_MESSAGES.get("sidebar_api_header", "üîê API Settings"))
API_KEY = (
    st.secrets.get("OPENAI_API_KEY") if "OPENAI_API_KEY" in st.secrets
    else st.sidebar.text_input(CFG_MESSAGES.get("api_key_label", "OpenAI API Key"), type="password")
)

# –í–µ—Ä—Å–∏—è SDK (–ø–æ–¥—Å–∫–∞–∑–∫–∞)
try:
    import openai as _openai
    st.sidebar.caption(f"OpenAI SDK: v{_openai.__version__}")
except Exception:
    pass

# –ú–æ–¥–µ–ª—å (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º)
model_options = get_model_options(API_KEY)
model = st.sidebar.selectbox(
    CFG_MESSAGES.get("model_label", "Model"),
    model_options,
    index=0,
    help=CFG_MESSAGES.get("model_help", ""),
)

# –ü—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–º–ø—Ç–∞
profile = st.sidebar.selectbox(
    CFG_MESSAGES.get("profile_label", "Prompt profile"),
    list(PROMPT_PROFILES.keys()),
    index=list(PROMPT_PROFILES.keys()).index("strict") if "strict" in PROMPT_PROFILES else 0,
)

# CEFR —É—Ä–æ–≤–µ–Ω—å
level = st.sidebar.selectbox(CFG_MESSAGES.get("cefr_label", "CEFR"), ["A1", "A2", "B1", "B2", "C1", "C2"], index=2)

# L1 —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–ø–µ—Ä–µ–≤–æ–¥—ã/–≥–ª–æ—Å—Å—ã)
L1_code = st.sidebar.selectbox(CFG_MESSAGES.get("l1_label", "Your language (L1)"), list(L1_LANGS.keys()), index=0)
L1_meta = L1_LANGS[L1_code]

# –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—é—Ç)
TMIN, TMAX, TDEF, TSTEP = CFG_TMIN, CFG_TMAX, CFG_TDEF, CFG_TSTEP
temperature = st.sidebar.slider(CFG_MESSAGES.get("temp_label", "Temperature"), TMIN, TMAX, TDEF, TSTEP)

# CSV/Anki export options
csv_with_header = st.sidebar.checkbox(
    CFG_MESSAGES.get("csv_header_checkbox", "CSV: –≤–∫–ª—é—á–∏—Ç—å —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞"),
    value=True,
    help=CFG_MESSAGES.get("csv_header_help", "")
)
_guid_label = st.sidebar.selectbox(
    CFG_MESSAGES.get("anki_guid_policy_label", "Anki GUID policy"),
    CFG_MESSAGES.get("anki_guid_policy_options", ["stable (update/skip existing)", "unique per export (import as new)"]),
    index=0,
    help=CFG_MESSAGES.get("anki_guid_policy_help", ""),
)

st.session_state["csv_with_header"] = csv_with_header
st.session_state["anki_guid_policy"] = "unique" if _guid_label.startswith("unique") else "stable"

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±–æ—Ä –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–π
st.session_state["prompt_profile"] = profile
st.session_state["level"] = level
st.session_state["L1_code"] = L1_code

# ==========================
# Demo / upload / state
# ==========================
if "input_data" not in st.session_state:
    st.session_state.input_data: List[Dict] = []
if "results" not in st.session_state:
    st.session_state.results: List[Dict] = []

st.title(CFG_MESSAGES.get("app_title", "üìò Anki CSV/Anki Builder ‚Äî Dutch Cloze Cards"))

# –î–µ–º–æ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
DEMO_WORDS = CFG_DEMO_WORDS

col_demo, col_clear = st.columns([1,1])
with col_demo:
    if st.button(CFG_MESSAGES.get("try_demo_button", "Try demo"), type="secondary"):
        st.session_state.input_data = DEMO_WORDS
        st.toast(CFG_MESSAGES.get("demo_loaded", "üîÅ Demo loaded"), icon="‚úÖ")
with col_clear:
    if st.button(CFG_MESSAGES.get("clear_button", "–û—á–∏—Å—Ç–∏—Ç—å"), type="secondary"):
        st.session_state.input_data = []
        st.session_state.results = []

# Upload
uploaded_file = st.file_uploader(CFG_MESSAGES.get("uploader_label", "Upload .txt / .md"), type=["txt", "md"], accept_multiple_files=False)

# ==========================
# Parsing –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
# ==========================

def parse_input(text: str) -> List[Dict]:
    rows: List[Dict] = []
    for raw in text.strip().splitlines():
        line = raw.strip()
        if not line:
            continue
        # 1) Markdown-—Ç–∞–±–ª–∏—Ü–∞: | **woord** | definitie NL | RU |
        if line.startswith("|") and "**" in line:
            parts = [p.strip() for p in line.strip("|").split("|")]
            if len(parts) >= 3:
                woord = re.sub(r"\*", "", parts[0]).strip()
                def_nl = parts[1].strip()
                ru_short = parts[2].strip()
                entry = {"woord": woord}
                if def_nl:
                    entry["def_nl"] = def_nl
                if ru_short:
                    entry["ru_short"] = ru_short
                rows.append(entry)
            continue
        # 4) TSV: woord \t def_nl
        if "\t" in line:
            tparts = [p.strip() for p in line.split("\t")]
            if len(tparts) == 2:
                rows.append({"woord": tparts[0], "def_nl": tparts[1]})
                continue
        # 2) –ü–æ—Å—Ç—Ä–æ—á–Ω—ã–π: woord ‚Äî def NL ‚Äî RU  |  woord ‚Äî def NL
        if " ‚Äî " in line:
            parts = [p.strip() for p in line.split(" ‚Äî ")]
            if len(parts) == 3:
                rows.append({"woord": parts[0], "def_nl": parts[1], "ru_short": parts[2]})
                continue
            if len(parts) == 2:
                rows.append({"woord": parts[0], "def_nl": parts[1]})
                continue
        # 3) –ü—Ä–æ—Å—Ç–æ —Å–ª–æ–≤–æ
        rows.append({"woord": line})
    return rows

if uploaded_file is not None:
    try:
        file_text = uploaded_file.read().decode("utf-8")
    except UnicodeDecodeError:
        uploaded_file.seek(0)
        file_text = uploaded_file.read().decode("utf-16")
    st.session_state.input_data = parse_input(file_text)

# Preview –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
if st.session_state.input_data:
    st.subheader(CFG_MESSAGES.get("recognized_rows_title", "üîç –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏"))
    st.dataframe(pd.DataFrame(st.session_state.input_data), use_container_width=True)
else:
    st.info(CFG_MESSAGES.get("upload_hint", "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ **Try demo**"))

# ==========================
# Helpers: sanitize, temperature policy, prompt compose
# ==========================

def sanitize(value: str) -> str:
    if value is None:
        return ""
    return str(value).replace("|", "‚à£").strip()


def _should_pass_temperature(model_id: str) -> bool:
    no_temp = st.session_state.get("no_temp_models", set())
    if model_id in no_temp:
        return False
    if model_id.startswith(("gpt-5", "o3")):
        return False
    return True


def _det_include_signalword(woord: str, level: str) -> bool:
    if level in ("B1", "B2", "C1", "C2"):
        seed = int(hashlib.sha256(f"{woord}|{level}".encode()).hexdigest(), 16) % 100
        return seed < 50  # ‚âà50%
    return False


# compose_instructions_en –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –∏–∑ prompts.py


# ==========================
# OpenAI call + validation/repair
# ==========================

def extract_json_block(text: str) -> Dict:
    if not text:
        return {}
    m = re.search(r"\{[\s\S]*\}", text)
    if not m:
        return {}
    try:
        return json.loads(m.group(0))
    except Exception:
        return {}


def validate_card(card: Dict) -> List[str]:
    problems = []
    required = ["L2_word", "L2_cloze", "L1_sentence", "L2_collocations", "L2_definition", "L1_gloss"]
    for k in required:
        v = card.get(k, "")
        if not isinstance(v, str) or not v.strip():
            problems.append(f"Field '{k}' is empty")
        if "|" in str(v):
            problems.append(f"Field '{k}' contains '|'")
    if "{{c1::" not in card.get("L2_cloze", ""):
        problems.append("Missing {{c1::‚Ä¶}} in L2_cloze")
    # collocations: exactly 3 items by '; '
    col_raw = card.get("L2_collocations", "")
    items = [s.strip() for s in re.split(r";\s*|\n+", col_raw) if s.strip()]
    if len(items) != 3:
        problems.append("L2_collocations must contain exactly 3 items")
    # L1_gloss: max 2 words
    if len(card.get("L1_gloss", "").split()) > 2:
        problems.append("L1_gloss must be 1‚Äì2 words")
    return problems


def call_openai_card(client: OpenAI, row: Dict, model: str, temperature: float, L1_code: str, level: str, profile: str) -> Dict:
    # Compose instructions (EN)
    instructions = compose_instructions_en(L1_code, level, profile)

    # Include signal word policy for current card (deterministic 50% for B1+)
    include_sig = _det_include_signalword(row.get("woord", ""), level)
    sig_list = SIGNALWORDS_B1 if level == "B1" else (SIGNALWORDS_B2_PLUS if level in ("B2", "C1", "C2") else [])

    payload = {
        "L2_word": row.get("woord", "").strip(),
        "given_L2_definition": row.get("def_nl", "").strip(),
        "preferred_L1_gloss": row.get("ru_short", "").strip(),  # backward compat
        "L1": L1_LANGS[L1_code]["name"],
        "CEFR": level,
        "INCLUDE_SIGNALWORD": include_sig,
        "ALLOWED_SIGNALWORDS": sig_list,
    }

    # –§–æ—Ä–º–∏—Ä—É–µ–º kwargs —Å —É—á—ë—Ç–æ–º –ø–æ–¥–¥–µ—Ä–∂–∫–∏ temperature
    kwargs = dict(
        model=model,
        instructions=instructions,
        input=(
            "Input data (JSON):\n" + json.dumps(payload, ensure_ascii=False) +
            "\nReturn STRICT JSON with fields: L2_word, L2_cloze, L1_sentence, L2_collocations, L2_definition, L1_gloss."
        ),
    )
    if _should_pass_temperature(model):
        kwargs["temperature"] = temperature

    try:
        resp = client.responses.create(**kwargs)
    except Exception as e:
        msg = str(e)
        if "Unsupported parameter: 'temperature'" in msg or "param': 'temperature'" in msg:
            no_temp = st.session_state.get("no_temp_models", set())
            no_temp.add(model)
            st.session_state.no_temp_models = no_temp
            kwargs.pop("temperature", None)
            resp = client.responses.create(**kwargs)
        else:
            raise

    parsed = extract_json_block(getattr(resp, "output_text", ""))

    # –°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è
    card = {
        "L2_word": sanitize(parsed.get("L2_word", payload["L2_word"])),
        "L2_cloze": sanitize(parsed.get("L2_cloze", "")),
        "L1_sentence": sanitize(parsed.get("L1_sentence", "")),
        "L2_collocations": sanitize(parsed.get("L2_collocations", "")),
        "L2_definition": sanitize(parsed.get("L2_definition", payload.get("given_L2_definition", ""))),
        "L1_gloss": sanitize(parsed.get("L1_gloss", payload.get("preferred_L1_gloss", ""))),
    }

    # –í–∞–ª–∏–¥–∞—Ü–∏—è + –æ–¥–∏–Ω repair-pass –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    problems = validate_card(card)
    if problems:
        repair_prompt = instructions + "\n\nREPAIR: The previous JSON has issues: " + "; ".join(problems) + ". " \
            + "Fix ONLY the problematic fields and return STRICT JSON again."
        repair_kwargs = dict(
            model=model,
            instructions=repair_prompt,
            input=("Previous JSON:\n" + json.dumps(card, ensure_ascii=False)),
        )
        if _should_pass_temperature(model):
            repair_kwargs["temperature"] = temperature
        try:
            resp2 = client.responses.create(**repair_kwargs)
        except Exception as e:
            msg = str(e)
            if "Unsupported parameter: 'temperature'" in msg or "param': 'temperature'" in msg:
                no_temp = st.session_state.get("no_temp_models", set())
                no_temp.add(model)
                st.session_state.no_temp_models = no_temp
                repair_kwargs.pop("temperature", None)
                resp2 = client.responses.create(**repair_kwargs)
            else:
                raise
        parsed2 = extract_json_block(getattr(resp2, "output_text", ""))
        if parsed2:
            card = {
                "L2_word": sanitize(parsed2.get("L2_word", card["L2_word"])),
                "L2_cloze": sanitize(parsed2.get("L2_cloze", card["L2_cloze"])),
                "L1_sentence": sanitize(parsed2.get("L1_sentence", card["L1_sentence"])),
                "L2_collocations": sanitize(parsed2.get("L2_collocations", card["L2_collocations"])),
                "L2_definition": sanitize(parsed2.get("L2_definition", card["L2_definition"])),
                "L1_gloss": sanitize(parsed2.get("L1_gloss", card["L1_gloss"])),
            }

    return card

# ==========================
# CSV –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —à–∞–ø–∫–∞ –ø–æ–¥ L1)
# ==========================

def generate_csv(results: List[Dict], L1_code: str, include_header: bool = True) -> str:
    meta = L1_LANGS[L1_code]
    csv_buffer = io.StringIO()
    writer = csv.writer(csv_buffer, delimiter='|', lineterminator='\n')

    if include_header:
        writer.writerow([
            CFG_CSV_HEADERS_FIXED.get("nl_word", "NL-—Å–ª–æ–≤–æ"),
            CFG_CSV_HEADERS_FIXED.get("nl_sentence_cloze", "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ NL (—Å cloze)"),
            f"{meta['csv_translation']} {meta['label']}",
            CFG_CSV_HEADERS_FIXED.get("collocations_nl", "–ö–æ–ª–ª–æ–∫–∞—Ü–∏–∏ (NL)"),
            CFG_CSV_HEADERS_FIXED.get("definition_nl", "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ NL"),
            f"{meta['csv_gloss']} {meta['label']}",
        ])
    for r in results:
        writer.writerow([
            r.get('L2_word',''),
            r.get('L2_cloze',''),
            r.get('L1_sentence',''),
            r.get('L2_collocations',''),
            r.get('L2_definition',''),
            r.get('L1_gloss',''),
        ])
    return csv_buffer.getvalue()

# ==========================
# Anki .apkg export (genanki)
# ==========================

ANKI_MODEL_ID = CFG_ANKI_MODEL_ID
ANKI_DECK_ID = CFG_ANKI_DECK_ID

FRONT_HTML_TEMPLATE = CFG_FRONT_HTML_TEMPLATE
BACK_HTML_TEMPLATE = CFG_BACK_HTML_TEMPLATE
CSS_STYLING = CFG_CSS_STYLING


def _compute_guid(c: Dict, policy: str, run_id: str) -> str:
    base = f"{c.get('L2_word','')}|{c.get('L2_cloze','')}"
    if policy == "unique":
        base = base + "|" + run_id
    try:
        import genanki as _g
        return _g.guid_for(base)
    except Exception:
        # Fallback: –∫–æ—Ä–æ—Ç–∫–∏–π SHA1
        return hashlib.sha1(base.encode('utf-8')).hexdigest()[:10]

def build_anki_package(cards: List[Dict], L1_label: str, guid_policy: str, run_id: str) -> bytes:
    if not HAS_GENANKI:
        raise RuntimeError("genanki is not installed. Add 'genanki' to requirements.txt and redeploy.")

    # –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ö–∏–Ω—Ç–∞
    front = FRONT_HTML_TEMPLATE.replace("{L1_LABEL}", L1_label)
    back = BACK_HTML_TEMPLATE

    model = genanki.Model(
        ANKI_MODEL_ID,
        CFG_ANKI_MODEL_NAME,
        fields=[
            {"name": "L2_word"},
            {"name": "L2_cloze"},
            {"name": "L1_sentence"},
            {"name": "L2_collocations"},
            {"name": "L2_definition"},
            {"name": "L1_gloss"},
            {"name": "L1_hint"},
        ],
        templates=[
            {
                "name": "Cloze",
                "qfmt": front,
                "afmt": back,
            }
        ],
        css=CSS_STYLING,
        model_type=genanki.Model.CLOZE,
    )

    deck = genanki.Deck(ANKI_DECK_ID, CFG_ANKI_DECK_NAME)

    for c in cards:
        note = genanki.Note(
            model=model,
            fields=[
                c.get("L2_word", ""),
                c.get("L2_cloze", ""),
                c.get("L1_sentence", ""),
                c.get("L2_collocations", ""),
                c.get("L2_definition", ""),
                c.get("L1_gloss", ""),
                c.get("L1_hint", ""),
            ],
            guid=_compute_guid(c, guid_policy, run_id),
            tags=list({
                f"CEFR::{st.session_state.get('level','')}",
                f"profile::{st.session_state.get('prompt_profile','')}",
                f"model::{st.session_state.get('model_id', '')}",
                f"L1::{st.session_state.get('L1_code','RU')}",
            })
        )
        deck.add_note(note)

    pkg = genanki.Package(deck)
    # –ï—Å–ª–∏ –ø–æ–∑–∂–µ –±—É–¥—É—Ç –º–µ–¥–∏–∞ ‚Äî pkg.media_files = [...]
    bio = io.BytesIO()
    pkg.write_to_file(bio)
    return bio.getvalue()

# ==========================
# Generate section
# ==========================
if st.session_state.input_data:
    if st.button(CFG_MESSAGES.get("generate_button", "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–æ—á–∫–∏"), type="primary"):
        if not API_KEY:
            st.error(CFG_MESSAGES.get("no_api_key", "–£–∫–∞–∂–∏ OPENAI_API_KEY –≤ Secrets –∏–ª–∏ –≤ –ø–æ–ª–µ —Å–ª–µ–≤–∞."))
        else:
            client = OpenAI(api_key=API_KEY)
            # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º run_id –¥–ª—è GUID'–æ–≤ –≤ —ç—Ç–æ–º –ø—Ä–æ–≥–æ–Ω–µ
            st.session_state.anki_run_id = st.session_state.get("anki_run_id") or str(int(time.time()))
            st.session_state.results = []
            st.session_state.model_id = model
            total = len(st.session_state.input_data)
            progress = st.progress(0)
            for idx, row in enumerate(st.session_state.input_data):
                try:
                    card = call_openai_card(
                        client, row, model=model, temperature=temperature,
                        L1_code=L1_code, level=level, profile=profile
                    )
                    st.session_state.results.append(card)
                except Exception as e:
                    st.error(CFG_MESSAGES.get("error_card_processing_fmt", "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–ª–æ–≤–∞ '{woord}': {error}").format(woord=row.get('woord','?'), error=e))
                finally:
                    progress.progress(int((idx + 1) / max(total,1) * 100))
                    if CFG_API_DELAY > 0:
                        time.sleep(CFG_API_DELAY)

# ==========================
# Preview & downloads
# ==========================
if st.session_state.results:
    st.subheader(CFG_MESSAGES.get("preview_title_fmt", "üìã –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∫–∞—Ä—Ç–æ—á–µ–∫ (–ø–µ—Ä–≤—ã–µ {limit})").format(limit=CFG_PREVIEW_LIMIT))
    preview_df = pd.DataFrame(st.session_state.results)[:CFG_PREVIEW_LIMIT]
    st.dataframe(preview_df, use_container_width=True)

    # CSV download
    csv_data = generate_csv(st.session_state.results, L1_code, include_header=st.session_state.get('csv_with_header', True))
    st.download_button(
        label=CFG_MESSAGES.get("csv_download_label", "üì• –°–∫–∞—á–∞—Ç—å anki_cards.csv"),
        data=csv_data,
        file_name="anki_cards.csv",
        mime="text/csv",
    )

    # APKG download
    if HAS_GENANKI:
        try:
            anki_bytes = build_anki_package(
                st.session_state.results,
                L1_label=L1_meta["label"],
                guid_policy=st.session_state.get("anki_guid_policy", "stable"),
                run_id=st.session_state.get("anki_run_id", str(int(time.time())))
            )
            st.download_button(
                label=CFG_MESSAGES.get("apkg_download_label", "üß© –°–∫–∞—á–∞—Ç—å –∫–æ–ª–æ–¥—É Anki (.apkg)"),
                data=anki_bytes,
                file_name="dutch_cloze.apkg",
                mime="application/octet-stream",
            )
        except Exception as e:
            st.error(CFG_MESSAGES.get("error_apkg_build_fmt", "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å .apkg: {error}").format(error=e))
    else:
        st.info(CFG_MESSAGES.get("apkg_install_hint", "–î–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ .apkg –¥–æ–±–∞–≤—å –≤ requirements.txt —Å—Ç—Ä–æ–∫—É 'genanki' –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ."))

# ==========================
# Footer
# ==========================
st.caption(CFG_MESSAGES.get("footer_tips", ""))
